{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eac385a-4503-4990-929b-c82b222115de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f924e12-252d-4453-a92f-fef758a855ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Tou7and/slp-nutshell/main/text_classification/data/facebook_tsai/positive.txt\n",
    "!wget https://raw.githubusercontent.com/Tou7and/slp-nutshell/main/text_classification/data/facebook_tsai/negative.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388794d5-57c3-4b85-8d1f-d4137cab5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_unigram(text):\n",
    "    words = list(text)\n",
    "    return words\n",
    "\n",
    "def keep_mandarin(sent):\n",
    "    pattern_zh = re.compile(u'[⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]')\n",
    "    results = pattern_zh.finditer(sent)\n",
    "\n",
    "    zh_chars = []\n",
    "    for result in results:\n",
    "        # print(result.group(), result.span())\n",
    "        zh_chars.append(result.group())\n",
    "    sent_new = \"\".join(zh_chars)\n",
    "    return sent_new\n",
    "\n",
    "\n",
    "def load_data_from_file(text_file):\n",
    "    with open(text_file, 'r') as reader:\n",
    "        lines = reader.readlines()\n",
    "    \n",
    "    corpus = []\n",
    "    for line in lines:\n",
    "        corpus.append(keep_mandarin(line))\n",
    "    return corpus\n",
    "\n",
    "def load_sentiment_data_from_file(pos_file, neg_file):\n",
    "    \"\"\" Return corpus and corresponding labels \"\"\"\n",
    "    pos_data = load_data_from_file(pos_file)\n",
    "    neg_data = load_data_from_file(neg_file)\n",
    "\n",
    "    # pos_train = pos_data[:len(pos_data)-100]\n",
    "    pos_train = pos_data[:150]\n",
    "    pos_test = pos_data[-100:]\n",
    "    # neg_train = neg_data[:len(neg_data)-100]\n",
    "    neg_train = neg_data[:150]\n",
    "    neg_test = neg_data[-100:]\n",
    "\n",
    "    corpus_train = pos_train + neg_train\n",
    "    labels_train  = [\"pos\"]*len(pos_train) + [\"neg\"]*len(neg_train)\n",
    "    corpus_test = pos_test + neg_test\n",
    "    labels_test  = [\"pos\"]*len(pos_test) + [\"neg\"]*len(neg_test)\n",
    "\n",
    "    dataset = {\n",
    "        \"train\": (corpus_train, labels_train),\n",
    "        \"test\": (corpus_test, labels_test),\n",
    "    }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5dce0a9-5a3b-4556-9cb4-9db52b3034c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['哈哈小英總統真的好帥', '辛苦了', '小英總統加油', '基隆的資深優質立委', '智仁勇'] \n",
      " ['你當總統候讓我很後悔投你一票當初所言的你做到了什麼還不是跟國民黨一樣肥缺都是身邊的親戚來當到現在沒看過你做的有當擔的事情太平島你卻是軟弱的人', '原來童軍也是藍綠戰場', '懸賞一億檢舉國民黨黨產都上任了還把黨派鬥爭放在第一位', '您好不要怪人民是自己沒有把事情做好都已經是大人了是非善惡因該要知道政府要対抗的不是人民是外來的國家侵略等自己要怎庅領導國家也要懂感恩阿彌陀佛', '當然新政府不一樣不護漁不護國土也不願自己少領']\n",
      "['pos', 'pos', 'pos', 'pos', 'pos'] \n",
      " ['neg', 'neg', 'neg', 'neg', 'neg']\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "dataset = load_sentiment_data_from_file(\n",
    "    \"./positive.txt\",\n",
    "    \"./negative.txt\"\n",
    ")\n",
    "\n",
    "# Split training and testing set\n",
    "train_corpus, train_labels = dataset[\"train\"]\n",
    "test_corpus, test_labels = dataset[\"test\"]\n",
    "\n",
    "# Check training data\n",
    "print(train_corpus[:5], \"\\n\", train_corpus[-5:])\n",
    "print(train_labels[:5], \"\\n\", train_labels[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac50f0d-e22a-44df-8e0f-c757b58b7067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一', '丁', '七', '三', '上', '下', '不', '且', '世', '並', '中', '主', '之', '九', '也', '亂', '了', '事', '二', '五', '些', '亡', '交', '享', '亮', '人', '什', '仁', '今', '介', '他', '付', '代', '令', '以', '件', '任', '份', '企', '伉', '伐', '休', '但', '佈', '位', '低', '住', '佑', '何', '佛', '作', '你', '佳', '來', '例', '依', '便', '係', '促', '保', '信', '個', '們', '倒', '候', '借', '假', '做', '停', '健', '偵', '備', '傲', '傳', '傷', '傻', '像', '億', '優', '儷', '元', '先', '光', '克', '免', '兒', '兔', '入', '內', '全', '兩', '八', '公', '六', '共', '兵', '其', '兼', '再', '凱', '出', '分', '切', '初', '判', '別', '利', '到', '制', '刻', '則', '前', '副', '劃', '劇', '力', '功', '加', '助', '努', '勇', '動', '務', '勞', '勢', '勾', '包', '化', '區', '千', '升', '午', '半', '協', '南', '博', '危', '即', '卻', '原', '厭', '厲', '去', '參', '又', '及', '友', '反', '取', '受', '口', '句', '另', '只', '叫', '可', '史', '司', '吃', '各', '合', '同', '名', '吐', '向', '否', '吧', '呀', '告', '呢', '周', '呵', '命', '和', '哀', '品', '哈', '員', '哥', '哦', '哪', '哲', '唱', '商', '啊', '問', '啦', '善', '喔', '單', '嗎', '嘴', '嚴', '囂', '四', '回', '因', '困', '國', '圖', '團', '土', '在', '地', '圾', '坦', '垃', '型', '域', '執', '基', '堅', '報', '場', '境', '增', '壓', '壞', '士', '外', '多', '夜', '夠', '大', '天', '太', '夫', '失', '奈', '奧', '女', '奴', '她', '好', '如', '妳', '始', '姐', '姓', '委', '娘', '媒', '媽', '子', '存', '孤', '孩', '孫', '學', '它', '安', '宋', '完', '宏', '官', '定', '客', '宣', '害', '家', '容', '寄', '富', '寡', '實', '寧', '審', '寫', '寬', '寶', '將', '專', '尉', '尊', '對', '導', '小', '少', '尤', '就', '局', '屁', '居', '屍', '展', '屬', '山', '岸', '島', '工', '差', '己', '已', '巴', '市', '希', '帥', '師', '席', '帳', '帶', '常', '幫', '平', '年', '幸', '幻', '幾', '底', '府', '度', '康', '庸', '廚', '廢', '建', '引', '弱', '張', '強', '彈', '彌', '形', '影', '往', '待', '很', '律', '後', '徐', '得', '從', '御', '復', '微', '徵', '德', '心', '必', '忍', '忘', '忙', '快', '念', '忽', '怎', '怕', '思', '急', '性', '怨', '怪', '恐', '恩', '您', '悲', '情', '惑', '惜', '惡', '想', '意', '愛', '感', '慈', '態', '慢', '慧', '慮', '憂', '憐', '憲', '懂', '應', '懷', '成', '我', '或', '戰', '所', '扁', '手', '才', '打', '批', '找', '承', '技', '把', '抓', '投', '抗', '抱', '押', '拒', '拓', '拼', '拿', '持', '指', '挺', '授', '接', '推', '提', '換', '搞', '搭', '搶', '撥', '擔', '據', '擱', '擺', '支', '收', '改', '攻', '放', '政', '故', '敏', '救', '敗', '教', '敢', '散', '整', '敵', '數', '文', '料', '斯', '新', '斷', '方', '於', '施', '族', '日', '早', '明', '昏', '是', '時', '晚', '景', '智', '暫', '更', '書', '替', '最', '會', '月', '有', '朋', '服', '望', '期', '未', '本', '李', '村', '東', '林', '果', '查', '柱', '核', '根', '格', '案', '條', '棄', '棒', '森', '楚', '業', '極', '樂', '標', '樣', '機', '權', '次', '欺', '歡', '止', '正', '此', '步', '武', '歲', '歷', '死', '殖', '段', '殺', '毅', '每', '毒', '比', '民', '氣', '水', '永', '求', '污', '決', '沒', '油', '治', '法', '注', '洗', '洪', '活', '派', '流', '浪', '海', '消', '深', '清', '減', '源', '準', '溝', '滅', '滇', '滿', '漁', '演', '漢', '濟', '灣', '火', '災', '為', '無', '然', '照', '熊', '營', '爭', '爲', '父', '物', '特', '牽', '犯', '狀', '猶', '獄', '獨', '獲', '率', '王', '現', '球', '理', '瑜', '生', '產', '用', '由', '界', '留', '略', '畫', '異', '當', '疑', '病', '登', '發', '百', '的', '皆', '益', '監', '目', '直', '相', '盾', '省', '看', '真', '眼', '着', '睛', '瞭', '知', '短', '砍', '破', '硬', '確', '示', '社', '祕', '祖', '祝', '神', '票', '福', '秀', '私', '科', '租', '稅', '種', '稱', '穩', '空', '穿', '突', '窮', '竊', '立', '童', '笑', '第', '等', '策', '算', '管', '節', '簡', '精', '糟', '紀', '約', '紅', '納', '級', '組', '結', '絕', '給', '統', '經', '綠', '維', '綱', '網', '緊', '緩', '緬', '縣', '總', '繳', '繼', '續', '纔', '缺', '罪', '罰', '署', '罵', '罷', '羅', '美', '義', '習', '翻', '老', '者', '而', '耶', '聯', '聲', '職', '聽', '肇', '肉', '肥', '育', '背', '能', '脫', '腿', '臉', '自', '至', '致', '臺', '與', '興', '舉', '船', '艦', '良', '艱', '色', '花', '苦', '英', '茶', '草', '莫', '菜', '菩', '華', '萬', '落', '著', '蓋', '蔡', '薩', '薪', '藍', '藥', '蘇', '處', '號', '血', '衆', '行', '街', '衛', '衝', '衣', '表', '衰', '被', '裁', '裏', '裝', '裡', '西', '要', '見', '規', '視', '親', '覺', '觀', '解', '言', '計', '討', '訓', '記', '訪', '設', '許', '詐', '評', '話', '該', '認', '誓', '誘', '語', '誤', '說', '課', '調', '談', '請', '論', '謀', '謊', '講', '謝', '證', '識', '警', '議', '護', '讀', '變', '讓', '讚', '豪', '豫', '貝', '負', '財', '貨', '貪', '貴', '買', '費', '資', '賢', '賣', '賤', '質', '賽', '走', '起', '超', '越', '趕', '足', '跟', '路', '跳', '身', '車', '軌', '軍', '載', '輕', '輝', '輩', '輪', '輸', '轉', '辛', '辜', '迎', '近', '迴', '迷', '追', '退', '送', '途', '這', '通', '速', '造', '連', '週', '進', '逼', '遇', '遊', '運', '過', '道', '違', '遠', '遭', '選', '還', '邊', '那', '部', '都', '鄭', '配', '酒', '釋', '重', '野', '量', '金', '釣', '銀', '錢', '錯', '鎮', '長', '門', '開', '間', '閩', '關', '阿', '陀', '降', '限', '院', '陰', '陳', '陷', '陸', '陽', '隆', '隊', '際', '障', '隨', '險', '隸', '雄', '集', '雖', '離', '難', '電', '需', '青', '非', '靠', '面', '革', '音', '響', '頂', '順', '須', '預', '領', '頭', '題', '願', '顧', '風', '飛', '飯', '餐', '首', '馬', '駕', '騙', '驕', '體', '高', '鬥', '鬼', '魂', '魚', '麗', '麼', '黃', '點', '黨', '齊']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 特徵: 使用 scikit learn 的 CountVectorizer (Bag-of-words)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "# 初始化\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_unigram, min_df=2)\n",
    "\n",
    "# just fit it\n",
    "vectorizer.fit(train_corpus)\n",
    "\n",
    "# 觀察學到的 feature\n",
    "print(vectorizer.get_feature_names_out().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c59918-e738-4618-a51e-479250b179d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set:  0.73\n"
     ]
    }
   ],
   "source": [
    "# Train a DecisionTree\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "# 用剛剛得到的 vectorizer 萃取特徵\n",
    "training_feats = vectorizer.transform(train_corpus)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "clf.fit(training_feats, train_labels)\n",
    "\n",
    "test_counts = vectorizer.transform(test_corpus).toarray()\n",
    "y_pred = []\n",
    "for kk in test_corpus:\n",
    "    kk_counts = vectorizer.transform([kk]).toarray()\n",
    "    y_pred.append(clf.predict(kk_counts)[0])\n",
    "\n",
    "# 看看 預測結果 跟 標準答案 的差距\n",
    "print(\"Accuracy on testing set: \", accuracy_score(y_pred, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0596b5-58ff-4cfb-a11f-cb86f8a1b7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "政府實在過於無能 ['pos']\n",
      "政府很有效率 ['pos']\n",
      "阿不就好棒棒 ['neg']\n",
      "索尼罪大惡極 百姓怨聲載道 ['pos']\n"
     ]
    }
   ],
   "source": [
    "# Inference some real samples\n",
    "samples = [\n",
    "    \"政府實在過於無能\",\n",
    "    \"政府很有效率\",\n",
    "    \"阿不就好棒棒\",\n",
    "    \"索尼罪大惡極 百姓怨聲載道\",\n",
    "]\n",
    "\n",
    "for sample in samples:\n",
    "    print(sample, clf.predict(vectorizer.transform([sample]).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de760f-d206-43bc-9dfb-025c908e10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Train a better classifier\n",
    "\n",
    "# Hint 1: try new features, ex. bag-of-bigram.\n",
    "# or try any other features you think of or find.\n",
    "# If you have no idea:\n",
    "# https://github.com/Tou7and/slp-nutshell/blob/main/text_classification/bag_of_ngrams.py\n",
    "\n",
    "def tokenize_bigram(text):\n",
    "    # Try to implement bigram\n",
    "    # Hints: loop through the text\n",
    "    bigrams = []\n",
    "    return bigrams\n",
    "\n",
    "vectorizer2 = CountVectorizer(tokenizer=tokenize_bigram, min_df=2)\n",
    "\n",
    "vectorizer2.fit(train_corpus)\n",
    "\n",
    "training_feats = vectorizer2.transform(train_corpus)\n",
    "\n",
    "\n",
    "# Hint 2: try new classifiers\n",
    "# You can replace the Decision Tree with any other classifiers you learned before.\n",
    "# If you have no idea:\n",
    "# https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html\n",
    "clf2 = DecisionTreeClassifier(random_state=0) # replace with other classifier\n",
    "\n",
    "clf2.fit(training_feats, train_labels)\n",
    "\n",
    "test_counts = vectorizer2.transform(test_corpus).toarray()\n",
    "y_pred = []\n",
    "for kk in test_corpus:\n",
    "    kk_counts = vectorizer2.transform([kk]).toarray()\n",
    "    y_pred.append(clf2.predict(kk_counts)[0])\n",
    "\n",
    "print(\"Accuracy on testing set: \", accuracy_score(y_pred, test_labels))\n",
    "\n",
    "samples = [\n",
    "    \"政府實在過於無能\",\n",
    "    \"政府很有效率\",\n",
    "    \"阿不就好棒棒\",\n",
    "    \"索尼罪大惡極 百姓怨聲載道\",\n",
    "]\n",
    "\n",
    "print()\n",
    "for sample in samples:\n",
    "    print(sample, clf2.predict(vectorizer2.transform([sample]).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffbecc1-272d-4f79-80a8-898563ddd66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
